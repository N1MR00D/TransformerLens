{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "\n",
    "import einops\n",
    "import torch\n",
    "from einops import einsum\n",
    "from jaxtyping import Float\n",
    "from transformer_lens import ActivationCache, HookedTransformer, HookedTransformerConfig\n",
    "from enum import Enum\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "device = \"mps\"\n",
    "model = HookedTransformer.from_pretrained(\"pythia-2.8b\", device=\"cpu\")\n",
    "model.to(device)\n",
    "model.set_use_attn_result(True)\n",
    "model.eval()\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(\"Michael jordan plays the sport of\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Enum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r3/qqfm7xmj3sl5nztnvkkpv8y00000gn/T/ipykernel_74960/595915870.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mComponentType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"Component Type.\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mType\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mcalculated\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdirect\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0mattribution\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Enum' is not defined"
     ]
    }
   ],
   "source": [
    "class ComponentType(Enum):\n",
    "    \"\"\"Component Type.\n",
    "\n",
    "    Type of a component, that we have calculated the direct logit attribution for.\n",
    "    \"\"\"\n",
    "\n",
    "    ATTENTION = \"attention\"\n",
    "    EMBED = \"embed\"\n",
    "    MLP = \"mlp\"\n",
    "    MLP_NEURON = \"mlp_neuron\"\n",
    "    MODEL = \"model\"\n",
    "    POSITIONAL_EMBED = \"positional_embed\"\n",
    "    SOURCE_TOKEN = \"source_token\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ComponentLabel:\n",
    "    \"\"\"Component Label.\n",
    "\n",
    "    Label for a specific component, that we have calculated the direct logit attribution for.\n",
    "\n",
    "    Note that where the tree depth is greater than 1, there will be multiple labels for the same\n",
    "    component (as the logit attribution will have been calculated multiple times, once for each\n",
    "    parent component).\n",
    "    \"\"\"\n",
    "\n",
    "    depth: int\n",
    "    head: Optional[int] = None\n",
    "    layer: Optional[int] = None\n",
    "    neuron: Optional[int] = None\n",
    "    parent_component: Optional[\"ComponentLabel\"] = None\n",
    "    position: Optional[int] = None\n",
    "    type: ComponentType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in cache.keys:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dla_by_layer(cache: ActivationCache, cfg: HookedTransformerConfig):\n",
    "    for layer in cfg.n_layers:\n",
    "        mlp_resid = cache[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
